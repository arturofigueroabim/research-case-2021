{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a7bd46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T17:39:05.271331Z",
     "start_time": "2022-01-12T17:39:03.329226Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.tokens import Doc, Span, Token\n",
    "import re\n",
    "#nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97a65bbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T17:39:05.283334Z",
     "start_time": "2022-01-12T17:39:05.273335Z"
    }
   },
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "import deplacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c869f62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T17:39:05.331337Z",
     "start_time": "2022-01-12T17:39:05.286333Z"
    }
   },
   "outputs": [],
   "source": [
    "essays = pd.read_csv(\"../data/output_csv/essays.csv\")\n",
    "adus = pd.read_csv(\"../data/output_csv/adus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0288b67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T17:39:05.335338Z",
     "start_time": "2022-01-12T17:39:05.332336Z"
    }
   },
   "outputs": [],
   "source": [
    "def text2doc(text):\n",
    "    return nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50901729",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T17:39:05.429745Z",
     "start_time": "2022-01-12T17:39:05.417745Z"
    },
    "tags": [
     "del"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Computer has negative effects to children\\n\\nNowadays, thanks to the development of technology, computer is now indispensable to life. Some people think that computer is good for children and it should be used daily by children but some others think differently. In my opinion, the latter opinion is true.\\nFirst, using computer constantly has bad influence on children's eyes. When they concentrate on computer for too long, their eyes will get tired, which is the main reason for some eyes problems, typically shortsighted.\\nMoreover, children who play games too much on computer can seriously lack communicating skills, they will know little about the outside life. It is a well-known fact that people who are addicted to games, especially online games, can eventually bear dangerous consequences. For instance, several teenagers play games without rest, which leads to health depression, a typical example is the death of Korean gamer, who had a non-stop playing for 3 days.\\nFinally, even people who are not interested in online game can still be negatively affected by using computer too much. Some social surveys have shown that a few children use computer for studying purpose, most of them are attracted by facebook, blog, etc. instead. Due to this neglect, they will have a bad result in school because when they can not live without internet, they will have no time for their studying.\\nIn conclusion, although it is undeniable that computer is a crucial part of human life, it still has its bad side, especially for children. People should learn how to use it properly to make it an effective tool because computer should be used not only for entertaining but also for working and studying purpose.\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = essays[essays['essay_id'] == 'essay024']['text'].iloc[0]\n",
    "\n",
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4081feb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T18:28:24.724779Z",
     "start_time": "2022-01-12T18:28:24.718781Z"
    },
    "tags": [
     "seg"
    ]
   },
   "outputs": [],
   "source": [
    "def segmentation(doc=None ,mode = 'sentence'):\n",
    "    if mode=='paragraph':\n",
    "        pass\n",
    "    if mode=='sentence':\n",
    "        return [sent for sent in doc.sents] #if not sent.text.isspace()]\n",
    "    if mode =='avg_n_grams':\n",
    "        # Code to segment with 15 grams here (aveage)    \n",
    "        pass\n",
    "    if mode=='clause':\n",
    "        # Code to segment by clause\n",
    "        pass\n",
    "    if mode=='token':\n",
    "        return [token for token in doc]# if not token.isspace()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af185a24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T18:30:56.736901Z",
     "start_time": "2022-01-12T18:30:56.326366Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "03df4751",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T18:31:49.056353Z",
     "start_time": "2022-01-12T18:31:49.006363Z"
    },
    "tags": [
     "editing",
     "func"
    ]
   },
   "outputs": [],
   "source": [
    "def get_num_tokens(units):\n",
    "    lis = []\n",
    "    for i in units:\n",
    "        lis.append(len(i))\n",
    "    return lis\n",
    "doc = nlp(input_text)\n",
    "units = segmentation(doc=doc)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0c9d7eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T18:32:11.004705Z",
     "start_time": "2022-01-12T18:32:10.997694Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      7\n",
       "1     16\n",
       "2     23\n",
       "3     10\n",
       "4      1\n",
       "5     13\n",
       "6     28\n",
       "7      1\n",
       "8     25\n",
       "9     25\n",
       "10    37\n",
       "11     1\n",
       "12    22\n",
       "13    29\n",
       "14    31\n",
       "15     1\n",
       "16    28\n",
       "17    31\n",
       "18     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis = get_num_tokens(units)\n",
    "\n",
    "pd.Series(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c55a6e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T17:39:54.841808Z",
     "start_time": "2022-01-12T17:39:54.824809Z"
    },
    "tags": [
     "editing"
    ]
   },
   "outputs": [],
   "source": [
    "def model(text):\n",
    "    \n",
    "    conj_advs = ['moreover', 'incidentally', 'next', 'yet', 'finally', 'then', 'for example', 'thus', 'accordingly', 'namely', 'meanwhile', 'that is', 'also', 'undoubtedly', 'all in all', 'lately', 'hence', 'still', 'therefore', 'in addition', 'indeed', 'again', 'so', 'nevertheless', 'besides', 'instead', 'for instance', 'certainly', 'however', 'anyway', 'further', 'furthermore', 'similarly', 'now', 'in conclusion', 'nonetheless', 'thereafter', 'likewise', 'otherwise', 'consequently']\n",
    "    doc_features = ['num_tokens']\n",
    "    span_features = ['word_emb', 'num_tokens', 'num_verbs', 'num_pos_pronouns', 'num_conj_adv', 'num_punct']\n",
    "    token_features =['word_emb']\n",
    "    features_dict = dict(doc_features=doc_features, span_features=span_features, token_features=token_features)\n",
    "    \n",
    "    \n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    def text2doc(text):\n",
    "        return nlp(text)\n",
    "    def segmentation(doc=None ,mode = 'sentence'):\n",
    "        if mode=='paragraph':\n",
    "            pass\n",
    "        if mode=='sentence':\n",
    "            return [sent for sent in doc.sents] #if not sent.text.isspace()]\n",
    "        if mode =='avg_n_grams':\n",
    "            # Code to segment with 15 grams here (aveage)    \n",
    "            pass\n",
    "        if mode=='clause':\n",
    "            # Code to segment by clause\n",
    "            pass\n",
    "        if mode=='token':\n",
    "            return [token for token in doc]# if not token.isspace()]\n",
    "        \n",
    "\n",
    "    def create_extensions(features_dict=None, force=True):\n",
    "\n",
    "        # Feature Getters\n",
    "\n",
    "        def get_word_emb(obj):\n",
    "            return obj.vector\n",
    "\n",
    "        def get_num_tokens(obj):\n",
    "            return len(obj)\n",
    "\n",
    "        def get_num_verbs(span):\n",
    "            return sum([1 for token in span if token.pos_ == \"VERB\"])\n",
    "\n",
    "        def get_num_pos_pronouns(span):\n",
    "            return sum([1 for token in span if token.tag_ == \"PRP$\"])\n",
    "\n",
    "        def get_num_pron(span):\n",
    "            return sum([1 for token in span if token.pos_ == \"PRON\"])\n",
    "\n",
    "        def get_num_conj_adv(span):\n",
    "            return sum([len(re.findall(adv, span.text.lower())) for adv in conj_advs])\n",
    "\n",
    "        def get_num_punct(span):\n",
    "            return sum([1 for token in span if token.tag_ == \"PUNCT\"])\n",
    "\n",
    "        # Set Extensions\n",
    "\n",
    "        for feature in features_dict['doc_features']:\n",
    "            Doc.set_extension(feature, force=force, getter=locals()[f\"get_{feature}\"])\n",
    "\n",
    "        for feature in features_dict['span_features']:\n",
    "            Span.set_extension(feature, force=force, getter=locals()[f\"get_{feature}\"])\n",
    "\n",
    "        for feature in features_dict['token_features']:\n",
    "            Token.set_extension(feature, force=force, getter=locals()[f\"get_{feature}\"])\n",
    "    doc=nlp(text)\n",
    "    #create_extensions(features_dict)\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2368042",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T17:40:00.124240Z",
     "start_time": "2022-01-12T17:39:59.656708Z"
    },
    "tags": [
     "editing"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.30964166, -0.15995926, -0.36976916,  0.02362831,  0.40009055,\n",
       "        0.48709768,  0.00876189,  0.03753388, -0.07180963, -0.40056404,\n",
       "        0.47985277,  0.03090625, -0.15748774, -0.13262661,  0.28944212,\n",
       "        0.33459133,  0.1137528 , -0.2453895 ,  0.2291998 , -0.3541542 ,\n",
       "        0.20109816,  0.06525717, -0.39157018,  0.3043734 ,  0.00339634,\n",
       "       -0.34089178,  0.4918148 , -0.11533842,  0.08570744,  0.09063318,\n",
       "       -0.5485939 , -0.05419394, -0.5263578 , -0.20897374,  0.12284336,\n",
       "        0.00788814, -0.30854517, -0.2587292 , -0.22838835, -0.08123485,\n",
       "       -0.38137683,  0.25916743, -0.37656832, -0.20672493, -0.12762463,\n",
       "        0.16307381,  0.62583566, -0.16401812,  0.1227967 , -0.06996056,\n",
       "        0.2060509 ,  0.22643924, -0.31613985,  0.31634232,  0.00141401,\n",
       "       -0.28840476,  0.25722772, -0.05864013,  0.1824341 ,  0.00700918,\n",
       "       -0.37478724, -0.19494373,  0.11228678, -0.3695145 ,  0.21960378,\n",
       "       -0.3254446 , -0.40394035,  0.16133498,  0.11756184, -0.1367383 ,\n",
       "       -0.2157695 ,  0.1465762 , -0.28730932, -0.49385244, -0.19804735,\n",
       "        0.37339425,  0.11019094, -0.17840084,  0.04177945,  0.15201303,\n",
       "       -0.48357806, -0.06525741,  0.26334935,  0.8259026 , -0.28659323,\n",
       "       -0.18260638,  0.0052822 ,  0.0496336 ,  0.2364085 , -0.34308162,\n",
       "       -0.5467131 ,  0.7005092 ,  0.26448625,  0.2879348 ,  0.30206063,\n",
       "       -0.15777683], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = essays[essays['essay_id'] == 'essay024']['text'].iloc[0]\n",
    "d = model(input_text)\n",
    "d[0:5]._.word_emb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6265d866",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T17:38:28.995543Z",
     "start_time": "2022-01-12T17:38:28.988542Z"
    },
    "tags": [
     "editing",
     "del"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.26657  , -0.13717  ,  0.23549  , -0.26712  ,  0.093324 ,\n",
       "        0.17563  , -0.33309  , -0.81744  ,  0.52655  ,  1.588    ,\n",
       "        0.078138 , -0.093094 , -0.27167  , -0.31207  , -0.35018  ,\n",
       "        0.072898 ,  0.032007 ,  2.5085   , -0.35727  , -0.018104 ,\n",
       "        0.26102  , -0.3157   , -0.46466  ,  0.029905 ,  0.576    ,\n",
       "       -0.34603  , -0.1502   , -0.23481  ,  0.20626  ,  0.28202  ,\n",
       "       -0.6897   , -0.17632  ,  0.40369  ,  0.40672  ,  0.13068  ,\n",
       "       -0.059988 , -0.3405   ,  0.46314  , -0.21149  ,  0.033152 ,\n",
       "        0.36526  ,  0.049521 , -0.096128 , -0.087093 , -0.12957  ,\n",
       "        0.22673  , -0.50435  , -0.50732  ,  0.27695  ,  0.14523  ,\n",
       "       -0.11455  , -0.13968  ,  0.38549  ,  0.26088  , -0.43217  ,\n",
       "       -0.45305  ,  0.072362 , -0.53383  ,  0.23317  ,  0.10471  ,\n",
       "        0.51278  , -0.05899  ,  0.06051  ,  0.22083  ,  0.63098  ,\n",
       "       -0.03232  , -0.36192  ,  0.45576  ,  0.037796 ,  0.21651  ,\n",
       "        0.44988  , -0.33074  ,  0.32553  , -0.30153  , -0.20416  ,\n",
       "       -0.14665  ,  0.16424  ,  0.13373  , -0.16779  ,  1.1746   ,\n",
       "       -0.10912  , -0.20507  ,  0.38651  , -0.35737  , -0.026643 ,\n",
       "        0.17325  , -0.2969   ,  0.67039  ,  0.75858  , -0.1168   ,\n",
       "       -0.13134  ,  0.38176  , -0.4658   ,  0.025771 ,  0.0082968,\n",
       "       -0.7205   ,  0.48854  ,  0.14139  , -0.2939   ,  0.24961  ,\n",
       "       -0.35349  ,  0.018458 ,  0.54134  ,  0.10035  , -0.076024 ,\n",
       "       -1.3677   ,  0.045979 ,  0.15556  ,  0.3356   ,  0.15967  ,\n",
       "        0.27533  ,  0.36783  ,  0.16304  , -0.11103  , -0.40265  ,\n",
       "       -0.058919 , -0.21596  ,  0.19496  ,  0.059413 ,  0.30387  ,\n",
       "        0.27047  ,  0.017042 ,  0.39704  , -0.13852  ,  0.12767  ,\n",
       "        0.41707  ,  0.24256  ,  0.91752  ,  0.45297  ,  0.56209  ,\n",
       "        0.54665  ,  0.29862  , -0.17171  ,  0.2429   , -0.039825 ,\n",
       "       -0.36826  , -0.173    ,  0.25535  , -0.072918 ,  0.077173 ,\n",
       "       -1.0758   , -0.059065 ,  0.1631   , -0.16374  ,  0.083568 ,\n",
       "        0.3455   , -0.072737 , -0.26645  , -0.3967   , -0.13455  ,\n",
       "        0.26312  , -0.20706  ,  0.18288  ,  0.11587  , -0.11174  ,\n",
       "        0.14654  ,  0.093874 ,  0.13199  ,  0.27867  , -0.6574   ,\n",
       "        0.13134  , -0.10831  ,  0.49168  , -0.056289 , -0.33275  ,\n",
       "       -0.15492  , -0.040728 ,  0.064694 , -0.032248 ,  0.61083  ,\n",
       "       -0.56753  ,  0.15492  ,  0.2884   , -0.084649 ,  0.18294  ,\n",
       "        0.17448  , -0.3491   , -0.10422  , -0.77571  ,  0.30476  ,\n",
       "       -0.095897 , -0.33695  ,  0.161    , -0.15076  ,  0.14437  ,\n",
       "        0.27484  ,  0.10077  ,  0.32409  ,  0.21695  , -0.53414  ,\n",
       "       -0.22338  , -0.43562  , -0.32303  ,  0.58586  , -0.23184  ,\n",
       "       -0.0181   ,  0.19989  , -0.35086  , -0.08002  ,  0.19299  ,\n",
       "        0.095799 ,  0.27447  ,  0.43433  , -0.098884 ,  0.14404  ,\n",
       "       -0.20874  ,  0.015602 ,  0.094597 ,  0.4834   ,  0.010013 ,\n",
       "       -0.14255  , -0.58035  , -0.30333  ,  0.051996 , -0.15122  ,\n",
       "       -0.37053  , -0.37321  , -0.034599 , -0.99269  , -0.15557  ,\n",
       "        0.12362  , -0.18469  , -0.29648  ,  0.014692 , -0.065477 ,\n",
       "       -0.13687  ,  0.39093  ,  0.56124  ,  0.42304  , -0.21074  ,\n",
       "       -0.3262   , -0.071347 ,  0.27527  , -0.18207  , -0.43537  ,\n",
       "        0.15757  ,  0.26226  , -0.37498  , -0.47008  ,  0.1778   ,\n",
       "        0.6498   ,  0.14257  ,  0.14552  , -0.12116  , -0.12345  ,\n",
       "       -0.65636  , -0.23754  ,  0.054897 , -0.34359  ,  0.26974  ,\n",
       "        0.29918  , -0.28367  ,  0.17973  ,  0.45228  ,  0.46051  ,\n",
       "       -0.51592  , -0.26155  ,  0.083629 , -0.066247 ,  0.13831  ,\n",
       "        0.57407  ,  0.55507  ,  0.063494 , -0.37227  , -0.47057  ,\n",
       "       -0.42985  , -0.64027  ,  0.071124 ,  0.86233  ,  0.05462  ,\n",
       "       -0.5722   , -0.17404  , -0.022872 , -0.30434  , -0.18376  ,\n",
       "        0.069443 , -0.25937  ,  0.22505  , -0.41308  , -0.90509  ,\n",
       "        0.19915  , -0.4752   ,  0.19739  ,  0.27136  , -0.21026  ,\n",
       "       -0.61475  , -0.092514 ,  0.048717 , -0.22783  , -0.60863  ,\n",
       "       -0.78686  , -0.16716  ,  0.37552  ,  0.57434  ,  0.055414 ,\n",
       "       -0.22545  ,  0.30528  ,  0.35608  , -0.46496  ,  0.13914  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0]._.word_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "497c7eea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T17:35:15.350029Z",
     "start_time": "2022-01-12T17:35:15.344029Z"
    }
   },
   "outputs": [],
   "source": [
    "def segmentation(doc=None ,mode = 'sentence'):\n",
    "    if mode=='paragraph':\n",
    "        pass\n",
    "    if mode=='sentence':\n",
    "        return [sent for sent in doc.sents] #if not sent.text.isspace()]\n",
    "    if mode =='avg_n_grams':\n",
    "        # Code to segment with 15 grams here (aveage)    \n",
    "        pass\n",
    "    if mode=='clause':\n",
    "        # Code to segment by clause\n",
    "        pass\n",
    "    if mode=='token':\n",
    "        return [token for token in doc]# if not token.isspace()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c957aeba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T17:35:20.300695Z",
     "start_time": "2022-01-12T17:35:20.297690Z"
    }
   },
   "outputs": [],
   "source": [
    "# # With Indexing\n",
    "# def segmentation(doc=None ,mode = 'sentence'):\n",
    "#     if mode=='paragraph':\n",
    "#         return \n",
    "#     if mode=='sentence':\n",
    "#         return [(i,sent) for i,sent in enumerate(doc.sents)] #if not sent.text.isspace()]\n",
    "#     if mode =='avg_n_grams':\n",
    "#         # Code to segment with 15 grams here (aveage)    \n",
    "#         pass\n",
    "#     if mode=='clause':\n",
    "#         # Code to segment by clause\n",
    "#         pass\n",
    "#     if mode=='token':\n",
    "#         return [token for token in doc]# if not token.isspace()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0dff752b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T17:35:20.494827Z",
     "start_time": "2022-01-12T17:35:20.490824Z"
    }
   },
   "outputs": [],
   "source": [
    "conj_advs = ['moreover', 'incidentally', 'next', 'yet', 'finally', 'then', 'for example', 'thus', 'accordingly', 'namely', 'meanwhile', 'that is', 'also', 'undoubtedly', 'all in all', 'lately', 'hence', 'still', 'therefore', 'in addition', 'indeed', 'again', 'so', 'nevertheless', 'besides', 'instead', 'for instance', 'certainly', 'however', 'anyway', 'further', 'furthermore', 'similarly', 'now', 'in conclusion', 'nonetheless', 'thereafter', 'likewise', 'otherwise', 'consequently']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9c42c22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T17:35:20.948042Z",
     "start_time": "2022-01-12T17:35:20.937040Z"
    }
   },
   "outputs": [],
   "source": [
    "doc_features = ['num_tokens']\n",
    "span_features = ['word_emb', 'num_tokens', 'num_verbs', 'num_pos_pronouns', 'num_conj_adv', 'num_punct']\n",
    "token_features =['word_emb']\n",
    "features_dict = dict(doc_features=doc_features, span_features=span_features, token_features=token_features)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_extensions(features_dict=None, force=True):\n",
    "    \n",
    "    # Feature Getters\n",
    "\n",
    "    def get_word_emb(obj):\n",
    "        return obj.vector\n",
    "    \n",
    "    def get_num_tokens(obj):\n",
    "        return len(obj)\n",
    "    \n",
    "    def get_num_verbs(span):\n",
    "        return sum([1 for token in span if token.pos_ == \"VERB\"])\n",
    "\n",
    "    def get_num_pos_pronouns(span):\n",
    "        return sum([1 for token in span if token.tag_ == \"PRP$\"])\n",
    "\n",
    "    def get_num_pron(span):\n",
    "        return sum([1 for token in span if token.pos_ == \"PRON\"])\n",
    "    \n",
    "    def get_num_conj_adv(span):\n",
    "        return sum([len(re.findall(adv, span.text.lower())) for adv in conj_advs])\n",
    "    \n",
    "    def get_num_punct(span):\n",
    "        return sum([1 for token in span if token.tag_ == \"PUNCT\"])\n",
    "    \n",
    "    # Set Extensions\n",
    "    \n",
    "    for feature in features_dict['doc_features']:\n",
    "        Doc.set_extension(feature, force=force, getter=locals()[f\"get_{feature}\"])\n",
    "        \n",
    "    for feature in features_dict['span_features']:\n",
    "        Span.set_extension(feature, force=force, getter=locals()[f\"get_{feature}\"])\n",
    "        \n",
    "    for feature in features_dict['token_features']:\n",
    "        Token.set_extension(feature, force=force, getter=locals()[f\"get_{feature}\"])\n",
    "        \n",
    "create_extensions(features_dict)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf9fc6c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T17:35:22.149397Z",
     "start_time": "2022-01-12T17:35:22.128394Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8036/363907993.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# RUNNING THE FUNCTIONS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0minput_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0messays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0messays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'essay_id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'essay024'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext2doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0munits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msegmentation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sentence'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8036/3620379061.py\u001b[0m in \u001b[0;36mtext2doc\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtext2doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'nlp' is not defined"
     ]
    }
   ],
   "source": [
    "# RUNNING THE FUNCTIONS\n",
    "input_text = essays[essays['essay_id'] == 'essay024']['text'].iloc[0]\n",
    "doc = text2doc(input_text)\n",
    "\n",
    "units = segmentation(doc=doc, mode='sentence')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27385f8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-01-12T17:35:22.972639Z",
     "start_time": "2022-01-12T17:35:22.961639Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'units' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8036/2874798576.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munits\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'units' is not defined"
     ]
    }
   ],
   "source": [
    "s = units[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5db448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bb2e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132200b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
