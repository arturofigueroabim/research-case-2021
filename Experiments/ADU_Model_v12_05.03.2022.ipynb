{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0350e9ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T18:55:47.531707Z",
     "start_time": "2022-03-05T18:55:38.024344Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.tokens import Doc, Span, Token\n",
    "import re\n",
    "import benepar\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "nlp.add_pipe(\"benepar\", config={\"model\": \"benepar_en3\"})\n",
    "nlp_trf = spacy.load('en_core_web_trf', disable=['tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner'])\n",
    "\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76e521c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T18:55:47.547242Z",
     "start_time": "2022-03-05T18:55:47.533763Z"
    }
   },
   "outputs": [],
   "source": [
    "#from spacy import displacy\n",
    "#import deplacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ac0fbbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T18:55:47.609530Z",
     "start_time": "2022-03-05T18:55:47.549240Z"
    }
   },
   "outputs": [],
   "source": [
    "doc_features = ['num_tokens', 'para_starts']\n",
    "span_features = ['word_emb', 'sent_emb', 'num_tokens', 'num_verbs', 'num_pos_pronouns', 'num_conj_adv', 'num_punct', 'is_para_start',\n",
    "                 'index_in_doc', 'num_claim_indicator', 'num_premise_indicator', 'has_question_mark', 'has_personal_pronoun',\n",
    "                 'has_possessive_pronoun', 'has_modal_verb', 'is_first_token_gerund', 'tree_depth', 'contextual_features_prev' ,'contextual_features_next']\n",
    "\n",
    "# getters that are not used as features\n",
    "span_utilities = ['prev_unit', 'idx_start', 'idx_end', ]\n",
    "# methods\n",
    "span_methods = ['get_nth_unit', 'get_prev_unit_attr', 'get_label_and_error', 'get_label', 'get_possible_labels']\n",
    "token_features =['word_emb']\n",
    "\n",
    "\n",
    "\n",
    "extensions_dict = dict(doc_features=doc_features, span_features=span_features+span_utilities,\n",
    "                       token_features=token_features, span_methods=span_methods)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_extensions(extensions_dict=None, force=True):\n",
    "    \n",
    "    # Features that take 'unit' as input refer to the segmentation, they do not work with just any span.\n",
    "    \n",
    "    # Property attributes\n",
    "    \n",
    "    # Store starting and ending indices of spans in the whole doc\n",
    "    # 1 list per each document: [(s1_start, s1_end), (s2_start, s2_end),.., (sn_start, sn_end)]\n",
    "    Doc.set_extension(\"units_index_list\", default=[],force=True)\n",
    "    \n",
    "    # Store essay_id within doc\n",
    "    Doc.set_extension(\"essay_id\", default=None, force=True)\n",
    "\n",
    "    \n",
    "    # Feature Getters\n",
    "    def get_possible_labels(unit, error_function='percentage_correctness'):\n",
    "        \"\"\"\n",
    "        Inputs: unit\n",
    "\n",
    "        Outputs: label for the unit and segmentation error\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        def overlap_case(unit_start, unit_end, adu_start, adu_end):\n",
    "            if adu_start >= unit_start and adu_end <= unit_end:\n",
    "                # Case 1, ADU is fully contained in UNIT\n",
    "                return 1\n",
    "\n",
    "            elif adu_start <= unit_start and adu_end <=unit_end and adu_end>=unit_start:\n",
    "\n",
    "                # Case 2, ADU starts before UNIT, start(Left) of ADU is cut\n",
    "                return 2\n",
    "\n",
    "            elif adu_start >= unit_start and adu_end >= unit_end and adu_start<unit_end:\n",
    "\n",
    "                # Case 3, ADU starts after UNIT, end(Right) of ADU is cut\n",
    "                return 3\n",
    "\n",
    "            elif adu_start < unit_start and adu_end > unit_end:\n",
    "\n",
    "                # Case 4, ADU starts before UNIT and ends after UNIT, both sides of ADU are cut\n",
    "                return 4\n",
    "\n",
    "            else: \n",
    "                # ADU does not overlap with UNIT\n",
    "                return False\n",
    "            \n",
    "\n",
    "        def percentage_correctness(unit, adu_start, adu_end, overlap_case):\n",
    "\n",
    "            if overlap_case==2:\n",
    "                adu_start = unit._.idx_start\n",
    "            elif overlap_case==3:\n",
    "                adu_end = unit._.idx_end\n",
    "            elif overlap_case==4:\n",
    "                adu_start = unit._.idx_start\n",
    "                adu_end = unit._.idx_end\n",
    "\n",
    "            adu = unit.doc.char_span(adu_start, adu_end, alignment_mode='expand')\n",
    "            \n",
    "\n",
    "            unit_ntokens = len(unit)\n",
    "            adu_ntokens = len(adu)\n",
    "            pct_correct = adu_ntokens/unit_ntokens\n",
    "            return pct_correct\n",
    "\n",
    "        def extended_accuracy(unit, adu_start, adu_end, overlap_case):\n",
    "            # Compares number of tokens to get the the correct ADU in proportional with UNIT length\n",
    "\n",
    "            if overlap_case==2:\n",
    "                adu_start = unit._.idx_start\n",
    "            if overlap_case==3:\n",
    "                adu_end = unit._.idx_end\n",
    "            adu = unit.doc.char_span(adu_start, adu_end, alignment_mode='expand')\n",
    "\n",
    "            unit_ntokens = len(unit)\n",
    "            adu_ntokens = len(adu)\n",
    "            diff_ntokens = np.abs(unit_ntokens - adu_ntokens)\n",
    "\n",
    "            return 1/((diff_ntokens+1)**(np.log2(diff_ntokens+1)/np.log2(unit_ntokens+1)))\n",
    "\n",
    "\n",
    "        if error_function.lower() == 'percentage_correctness':\n",
    "            err_func = percentage_correctness\n",
    "        elif error_function.lower() == 'extended_accuracy':\n",
    "            err_func = extended_accuracy\n",
    "        \n",
    "        unit_start = unit._.idx_start\n",
    "        unit_end = unit._.idx_end\n",
    "\n",
    "        essay_id = unit.doc._.essay_id\n",
    "\n",
    "        # DataFrame containing ADUs indices & labels, filtered for current essay_id\n",
    "        adus_doc = adus[adus['essay_id'] == essay_id]\n",
    "\n",
    "        def segmentation_error(unit, adu_start, adu_end, overlap_case, error_function):\n",
    "            \n",
    "            adu = unit.doc.char_span(adu_start, adu_end, alignment_mode='expand')\n",
    "            \n",
    "            # positive value = too many tokens in segment, unit should be shorter (include less non-adu tokens)\n",
    "            # negative value = too less tokens in segment, unit should be longer (include more adu tokens)\n",
    "            \n",
    "            left_tokens = adu.start - unit.start\n",
    "            right_tokens = unit.end - adu.end\n",
    "            \n",
    "            if error_function.lower() == 'percentage_correctness':\n",
    "                err_func = percentage_correctness\n",
    "            elif error_function.lower() == 'extended_accuracy':\n",
    "                err_func = extended_accuracy\n",
    "\n",
    "            \n",
    "            return (left_tokens, err_func(unit, adu_start, adu_end, overlap_case), right_tokens)\n",
    "            \n",
    "# v7 returns: (ADU_Type, (left_error_tokens, err_func, right_error_tokens))\n",
    "        label_and_error = [(row['ADU_type'], segmentation_error(unit, row['start_ind'],row['end_ind'], \n",
    "                          overlap_case(unit_start, unit_end,row['start_ind'], row['end_ind']), error_function),\n",
    "                          #(row['start_ind'], row['end_ind'])\n",
    "                           ) \n",
    "                         for row_ind, row in adus_doc.iterrows() \n",
    "                         if unit_start < row['end_ind'] and unit_end >= row['start_ind'] ]\n",
    "\n",
    "            \n",
    "# v6 returns: (ADU_Type, err_func)\n",
    "#\n",
    "#         label_and_error = [(row['ADU_type'], err_func(unit, row['start_ind'],row['end_ind'], \n",
    "#                           overlap_case(unit_start, unit_end,row['start_ind'], row['end_ind'])),\n",
    "#                           #(row['start_ind'], row['end_ind'])\n",
    "#                            ) \n",
    "#                          for row_ind, row in adus_doc.iterrows() \n",
    "#                          if unit_start <= row['end_ind'] and unit_end >= row['start_ind']]\n",
    "\n",
    "    #     # Contains information of the ADUs that overlap with the UNIT\n",
    "    #     # Structure: (adu_start, adu_end, overlap_case, ADU_type)\n",
    "    #     overlap_adus = [(row['start_ind'],\n",
    "    #                      row['end_ind'], \n",
    "    #                      overlap_case(unit_start, unit_end,row['start_ind'], row['end_ind']), \n",
    "    #                      row['ADU_type']) \n",
    "    #                      for row_ind, row in adus_doc.iterrows()\n",
    "    #           if unit_start <= row['end_ind'] and unit_end >= row['start_ind']]\n",
    "\n",
    "        return label_and_error\n",
    "\n",
    "    \n",
    "    def get_label(unit, label_mode='clpr', threshold=0):\n",
    "        error_tuple = unit._.get_possible_labels()\n",
    "\n",
    "        if len(error_tuple) == 0:\n",
    "            return \"Non-ADU\"\n",
    "        else:\n",
    "            # Get position of label with maximum accuracy\n",
    "            label_position = np.argmax([error[1] for label, error in error_tuple])\n",
    "            if error_tuple[label_position][1][1] > threshold:\n",
    "                if label_mode=='clpr':\n",
    "                    label = error_tuple[label_position][0]\n",
    "                elif label_mode=='adu':\n",
    "                    label = 'ADU'\n",
    "                    \n",
    "            else:\n",
    "                label = \"Non-ADU\"\n",
    "\n",
    "            return label\n",
    "        \n",
    "    def get_label_and_error(unit, error_function='percentage_correctness', label_mode='clpr', threshold=0):\n",
    "        error_tuple = unit._.get_possible_labels(error_function=error_function)\n",
    "\n",
    "        if len(error_tuple) == 0:\n",
    "            return (\"Non-ADU\", ())\n",
    "        else:\n",
    "            # Get position of label with maximum accuracy\n",
    "            label_position = np.argmax([error[1] for label, error in error_tuple])\n",
    "            if error_tuple[label_position][1][1] > threshold:\n",
    "                if label_mode=='clpr':\n",
    "                    assigned_label_and_error = (error_tuple[label_position][0], error_tuple[label_position][1])\n",
    "                elif label_mode=='adu':\n",
    "                    assigned_label_and_error = ('ADU', error_tuple[label_position][1])\n",
    "                    \n",
    "            else:\n",
    "                assigned_label_and_error = (\"Non-ADU\", ())\n",
    "\n",
    "            return assigned_label_and_error\n",
    "\n",
    "    def _NOT_USED_get_label_adu(span):\n",
    "        \n",
    "        # Gets ADU vs non-ADU LABEL for the span (intended only for sentences)\n",
    "\n",
    "        # Works if the span is larger or equal to the adu\n",
    "\n",
    "        # TODO:\n",
    "        # DOES NOT WORK IF SPAN IS SMALLER THAN ADU, OR IF ADU IS SPLIT BETWEEN TWO SPANS (NEEDS MORE WORK!!!)\n",
    "        # CLAIM VS PREMISE\n",
    "        essay_id = span.doc._.essay_id\n",
    "\n",
    "        span_start = span[0].idx\n",
    "        #  + len(span[-1]) to get to the end of the last word\n",
    "        span_end = span[-1].idx  + len(span[-1])\n",
    "        start_inds = adus[adus['essay_id'] == essay_id ]['start_ind'].values\n",
    "        end_inds = adus[adus['essay_id'] == essay_id ]['end_ind'].values\n",
    "\n",
    "        # Checks if starting index of span is smaller than ADU and the ending index of the span is larger than the ADU\n",
    "        return ((start_inds >= span_start) & (end_inds <= span_end)).any()\n",
    "\n",
    "    \n",
    "    def get_idx_start(unit):\n",
    "        return unit[0].idx\n",
    "    \n",
    "    def get_idx_end(unit):\n",
    "        return unit[-1].idx  + len(unit[-1])\n",
    "    \n",
    "    \n",
    "    def get_para_starts(doc):\n",
    "        # Units starting with \\n or preceding \\n are considered as paragraph starts\n",
    "        # if start is 0, start -1 goes back to the last token of the doc\n",
    "\n",
    "        # TODO\n",
    "        # para_ends can be obtained by shifing this list to the right by one position\n",
    "        \n",
    "        # PROBLEM! WORKS ONLY FOR SENTENCE SEGMENTATION\n",
    "        \n",
    "        return [int(doc[start].text =='\\n' or doc[start-1].text=='\\n') for start, end in doc._.units_index_list]\n",
    "    \n",
    "    def get_is_para_start(unit):\n",
    "        \n",
    "        para_starts = unit.doc._.para_starts\n",
    "        unit_ind = unit._.index_in_doc\n",
    "        \n",
    "        return para_starts[unit_ind]\n",
    "    \n",
    "    def get_has_personal_pronoun(unit):\n",
    "        \n",
    "        return 'PRP' in [token.tag_ for token in unit]\n",
    "    \n",
    "    def get_has_possessive_pronoun(unit):\n",
    "        \n",
    "        return 'PRP$' in [token.tag_ for token in unit]     \n",
    "    \n",
    "    def get_has_modal_verb(unit):\n",
    "        \n",
    "        return 'MD' in [token.tag_ for token in unit]            \n",
    "    \n",
    "    def get_word_emb(obj):\n",
    "        return obj.vector\n",
    "    \n",
    "    def get_sent_emb(unit):\n",
    "        \n",
    "        trf_doc = nlp_trf(unit.text)\n",
    "        return trf_doc._.trf_data.tensors[1][0]\n",
    "        \n",
    "    \n",
    "    def get_num_tokens(obj):\n",
    "        return len(obj)\n",
    "    \n",
    "    def get_num_verbs(span):\n",
    "        return sum([1 for token in span if token.pos_ == \"VERB\"])\n",
    "\n",
    "    def get_num_pos_pronouns(span):\n",
    "        return sum([1 for token in span if token.tag_ == \"PRP$\"])\n",
    "\n",
    "    def get_num_pron(span):\n",
    "        return sum([1 for token in span if token.pos_ == \"PRON\"])\n",
    "    \n",
    "    def get_num_conj_adv(span):\n",
    "        conj_advs = ['moreover', 'incidentally', 'next', 'yet', 'finally', 'then', 'for example', 'thus', 'accordingly', 'namely', 'meanwhile', 'that is', 'also', 'undoubtedly', 'all in all', 'lately', 'hence', 'still', 'therefore', 'in addition', 'indeed', 'again', 'so', 'nevertheless', 'besides', 'instead', 'for instance', 'certainly', 'however', 'anyway', 'further', 'furthermore', 'similarly', 'now', 'in conclusion', 'nonetheless', 'thereafter', 'likewise', 'otherwise', 'consequently']\n",
    "        return sum([1 for adv in conj_advs if adv in span.text.lower()])\n",
    "    \n",
    "        \n",
    "    def get_num_claim_indicator(span):\n",
    "        claim_indicators = [\"accordingly\", \"as a result\", \"consequently\", \"conclude that\", \"clearly\", \"demonstrates that\", \"entails\", \"follows that\", \"hence\", \"however\", \"implies\", \"in fact\", \"in my opinion\", \"in short\", \"in conclusion\", \"indicates that\", \"it follows that\", \"it is highly probable that\", \"it is my contention\", \"it should be clear that\", \"I believe\", \"I mean\", \"I think\", \"must be that\", \"on the contrary\", \"points to the conclusions\", \"proves that\", \"shows that\", \"so\", \"suggests that\", \"the most obvious explanation\", \"the point I’m trying to make\", \"therefore\", \"thus\", \"the truth of the matter\", \"to sum up\", \"we may deduce\"]\n",
    "        \n",
    "        return sum([1 for c_indicator in claim_indicators if c_indicator in span.text.lower()])\n",
    "    \n",
    "    def get_num_premise_indicator(span):\n",
    "        premise_indicators=[\"after all\", \"assuming that\", \"as\", \"as indicated by\", \"as shown\", \"besides\", \"because\", \"deduced\", \"derived from\", \"due to\", \"firstly\", \"follows from\", \"for\", \"for example\", \"for instance\", \"for one thing\", \"for the reason that\", \"furthermore\", \"given that\", \"in addition\", \"in light of\", \"in that\", \"in view of\", \"in view of the fact that\", \"indicated by\", \"is supported by\", \"may be inferred\", \"moreover\", \"owing to\", \"researchers found that\", \"secondly\", \"this can be seen from\", \"since\", \"since the evidence is\", \"what’s more\", \"whereas\",]\n",
    "        return sum([1 for p_indicator in premise_indicators if p_indicator in span.text.lower()])\n",
    "    \n",
    "    def get_is_first_token_gerund(span):\n",
    "        \n",
    "        return span[0].tag_ =='VBG'\n",
    "    \n",
    "    def get_has_question_mark(span):\n",
    "        return '?' in span.text\n",
    "\n",
    "    def get_num_punct(span):\n",
    "        return sum([1 for token in span if token.tag_ == \".\"])\n",
    "    \n",
    "    def get_tree_depth(unit):\n",
    "        depths = {}\n",
    "\n",
    "        def walk_tree(node, depth):\n",
    "            depths[node.orth_] = depth\n",
    "            if node.n_lefts + node.n_rights > 0:\n",
    "                return [walk_tree(child, depth + 1) for child in node.children]\n",
    "\n",
    "        walk_tree(unit.root, 0)\n",
    "        return max(depths.values())\n",
    "    \n",
    "\n",
    "    def get_index_in_doc(span):\n",
    "        \"\"\"Gets index of the segmented unit in the doc\"\"\"\n",
    "        span_start = span.start\n",
    "\n",
    "        # span end not used yet\n",
    "        span_end = span.end\n",
    "\n",
    "        # finds where span_start is in units_index_list [(s1_start, s1_end), (s2_start, s2_end),.., (sn_start, sn_end)]\n",
    "        # returns the index of the corresponding span\n",
    "        return np.where([span.start in range(start, end) for start, end in span.doc._.units_index_list])[0][-1]\n",
    "\n",
    "\n",
    "    def get_prev_unit(span):\n",
    "\n",
    "        return span._.get_nth_unit(span._.index_in_doc-1)\n",
    "    \n",
    "        \n",
    "    def get_nth_unit(span, n):\n",
    "\n",
    "        # Tuple containing the start and end index of the nth span\n",
    "        span_index = span.doc._.units_index_list[n]\n",
    "\n",
    "        # Return nth span\n",
    "        return span.doc[span_index[0]: span_index[1]]\n",
    "\n",
    "    def get_prev_unit_attr(span, attribute):\n",
    "\n",
    "        return span._.prev_unit._.get(attribute)\n",
    "\n",
    "    def get_contextual_features_prev(unit):\n",
    "        contextual_features_names=['num_tokens','num_verbs','num_pos_pronouns','num_conj_adv','num_punct','is_para_start','num_claim_indicator','num_premise_indicator','has_question_mark','has_personal_pronoun','has_possessive_pronoun','has_modal_verb','is_first_token_gerund','tree_depth']\n",
    "        \n",
    "        contextual_features = np.array([])\n",
    "        for feature in contextual_features_names:\n",
    "            if unit._.index_in_doc==0:\n",
    "                contextual_features = np.append(contextual_features,0)\n",
    "            else:\n",
    "                contextual_features = np.append(contextual_features, unit._.prev_unit._.get(feature))\n",
    "        return contextual_features\n",
    "\n",
    "    def get_contextual_features_next(unit):\n",
    "        contextual_features_names=['num_tokens','num_verbs','num_pos_pronouns','num_conj_adv','num_punct','is_para_start','num_claim_indicator','num_premise_indicator','has_question_mark','has_personal_pronoun','has_possessive_pronoun','has_modal_verb','is_first_token_gerund','tree_depth']\n",
    "        \n",
    "        contextual_features = np.array([])\n",
    "\n",
    "        try:\n",
    "            next_unit = unit._.get_nth_unit(unit._.index_in_doc + 1)\n",
    "        except:\n",
    "            return [0 for feature in contextual_features_names]\n",
    "        else:\n",
    "            return [next_unit._.get(feature) for feature in contextual_features_names]\n",
    "\n",
    "            \n",
    "    \n",
    "    \n",
    "    # Iterate list of features and Set Extensions (Just to not manually set extensions one by one)\n",
    "    \n",
    "    for feature in extensions_dict['doc_features']:\n",
    "        Doc.set_extension(feature, force=force, getter=locals()[f\"get_{feature}\"])\n",
    "        \n",
    "    for feature in extensions_dict['span_features']:\n",
    "        Span.set_extension(feature, force=force, getter=locals()[f\"get_{feature}\"])\n",
    "        \n",
    "    for feature in extensions_dict['token_features']:\n",
    "        Token.set_extension(feature, force=force, getter=locals()[f\"get_{feature}\"])\n",
    "        \n",
    "    for method in extensions_dict['span_methods']:\n",
    "        Span.set_extension(method, force=force, method=locals()[method])\n",
    "\n",
    "\n",
    "def segmentation(doc=None ,mode = 'sentence', n_grams=15):\n",
    "    if mode=='paragraph':\n",
    "        pass\n",
    "    elif mode=='sentence':\n",
    "        # segment by sentences\n",
    "        units = [sent for sent in doc.sents  if not (sent.text.isspace() or sent.text =='')] \n",
    "        \n",
    "        # keep track of (start, end) of units in doc object\n",
    "        doc._.units_index_list = [(unit.start, unit.end) for unit in units]\n",
    "        return units\n",
    "    \n",
    "    elif mode =='n_grams':\n",
    "        # Code to segment with 15 grams here (average)  \n",
    "        units = [doc[i:i+n_grams] for i in range(len(doc))]\n",
    "\n",
    "        doc._.units_index_list = [(unit.start, unit.end) for unit in units]\n",
    "\n",
    "        return units\n",
    "    \n",
    "    elif mode=='clause':\n",
    "        # Code to segment by clause\n",
    "        pass\n",
    "    elif mode=='constituency1':\n",
    "        # Take the first level subordinating conjunction (SBAR)\n",
    "        # The first dependent clause\n",
    "        units = []\n",
    "        for sent in doc.sents:\n",
    "            for node in sent._.constituents:\n",
    "\n",
    "                if \"SBAR\" in node._.labels:\n",
    "\n",
    "                    # Before SBAR\n",
    "                    units.append(sent.doc[sent.start:node.start])\n",
    "                    # SBAR\n",
    "                    units.append(sent.doc[node.start:node.end])\n",
    "\n",
    "                    # After SBAR\n",
    "                    units.append(sent.doc[node.end:sent.end])\n",
    "\n",
    "                    # Break out to take only the first SBAR we encounter\n",
    "                    break\n",
    "        \n",
    "        units = [unit for unit in units if unit.text != '']\n",
    "        doc._.units_index_list = [(unit.start, unit.end) for unit in units]\n",
    "        \n",
    "        return units\n",
    "        \n",
    "    elif mode=='token':\n",
    "        return [token for token in doc if not (token.text.isspace() or token.text =='')]\n",
    "    elif mode=='gold_standard':\n",
    "        \n",
    "        # Segments ADUs according to annotations\n",
    "        \n",
    "        adu_inds = adus[adus['essay_id']==doc._.essay_id].sort_values('start_ind')[['start_ind','end_ind']]\n",
    "\n",
    "        units = []\n",
    "\n",
    "        start = 0\n",
    "        for i, row in adu_inds.iterrows():\n",
    "\n",
    "            # From previous adu end to current adu start (Non-ADU)\n",
    "            end = row['start_ind']-1\n",
    "\n",
    "            units.append(doc.char_span(start,end, alignment_mode='expand'))\n",
    "\n",
    "            start = row['start_ind']\n",
    "            end = row['end_ind']\n",
    "\n",
    "            # From current adu start to current adu end\n",
    "            units.append(doc.char_span(start,end,  alignment_mode='expand'))\n",
    "\n",
    "            # set current adu end as start for next iteration\n",
    "            start = row['end_ind']\n",
    "        \n",
    "        \n",
    "        # keep track of (start, end) of units in doc object\n",
    "        doc._.units_index_list = [(unit.start, unit.end) for unit in units]\n",
    "        \n",
    "        return units\n",
    "\n",
    "def unit2fv(unit, feature_list):\n",
    "    \n",
    "    fv = np.array([unit._.get(feature) for feature in feature_list], dtype='object')\n",
    "    \n",
    "    _fv = np.array([np.reshape(feature, -1) for feature in fv], dtype='object')\n",
    "    \n",
    "    return np.concatenate(_fv)\n",
    "\n",
    "\n",
    "def calculate_segmentation_accuracy(units, error_function='percentage_correctness'):\n",
    "    \n",
    "    \n",
    "    \n",
    "    start_errors = np.array([])\n",
    "    segmentation_accs = np.array([])\n",
    "    end_errors = np.array([])\n",
    "\n",
    "    for unit in units:\n",
    "        error_tuple = unit._.get_possible_labels(error_function=error_function)\n",
    "\n",
    "        if len(error_tuple) != 0:\n",
    "            label_position = np.argmax([error[1] for label, error in error_tuple])\n",
    "\n",
    "            start_errors = np.append(start_errors,error_tuple[label_position][1][0])\n",
    "\n",
    "            segmentation_accs = np.append(segmentation_accs, error_tuple[label_position][1][1])\n",
    "\n",
    "            end_errors = np.append(end_errors, error_tuple[label_position][1][2])\n",
    "\n",
    "\n",
    "\n",
    "    start_error = sum((start_errors**2))/len(start_errors)\n",
    "\n",
    "    end_error = sum((end_errors**2))/len(end_errors)\n",
    "\n",
    "    segmentation_acc = segmentation_accs.mean()\n",
    "    \n",
    "    return (start_error, segmentation_acc, end_error)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Run\n",
    "create_extensions(extensions_dict)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1abd7fc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T18:55:47.625530Z",
     "start_time": "2022-03-05T18:55:47.612512Z"
    }
   },
   "outputs": [],
   "source": [
    "# Optional, not used yet. Trying to solve problem that title gets included with the first sentence\n",
    "def add_full_stops(text):\n",
    "    \"\"\"adds full stops to texts that end with \\n missing full stops\"\"\"\n",
    "    return re.sub(\"\\n+(?!\\.)\",'.\\n', text)\n",
    "# Not used\n",
    "def text2doc(text):\n",
    "    # need to use nlp.pipe here instead\n",
    "    return nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "010a19ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T19:36:13.874349Z",
     "start_time": "2022-03-05T19:36:13.854344Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pipelinev1\n",
    "\n",
    "def text2fv(df, segmentation_mode='sentence', label_mode='adu', threshold=0, n_grams=None ,print_segmentation_error = False):\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Rename to create_training_data?\n",
    "    data = [(row['text'], dict(id=row['essay_id'])) for ind, row in df.iterrows()]\n",
    "    docs = []\n",
    "    \n",
    "    if segmentation_mode != \"constituency1\":\n",
    "    \n",
    "        for doc, context in nlp.pipe(data, as_tuples=True, disable=['benepar']):\n",
    "            doc._.essay_id = context['id']\n",
    "            docs.append(doc)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        for doc, context in nlp.pipe(data, as_tuples=True):\n",
    "            doc._.essay_id = context['id']\n",
    "            docs.append(doc)\n",
    "\n",
    "    segmented_docs = [segmentation(doc, mode=segmentation_mode ,n_grams=n_grams) for doc in docs]\n",
    "    \n",
    "    # Flatten lists (Dissolve docs boundaries and store all units together in one huge list)\n",
    "    units = list(chain.from_iterable(segmented_docs))\n",
    "    \n",
    "    if print_segmentation_error:\n",
    "        print(f\"Segmentation Mode: {segmentation_mode}\\nAccuracy:{calculate_segmentation_accuracy(units)}\")\n",
    "\n",
    "    X_features = span_features\n",
    "    \n",
    "\n",
    "    X = np.array([unit2fv(unit, X_features) for unit in units])\n",
    "    #y = np.array([unit._.get_label(label_mode=label_mode, threshold=threshold) for unit in units])\n",
    "    y_adu = np.array([unit._.get_label(label_mode='adu', threshold=threshold) for unit in units])\n",
    "    y_clpr = np.array([unit._.get_label(label_mode='clpr', threshold=threshold) for unit in units])\n",
    "    \n",
    "    return X, y_adu, y_clpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1473cad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T19:36:17.540450Z",
     "start_time": "2022-03-05T19:36:16.398795Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# INPUTS \n",
    "essays = pd.read_csv(\"../data/output_csv/essays.csv\")\n",
    "adus = pd.read_csv(\"../data/output_csv/adus.csv\")\n",
    "\n",
    "###### TEST\n",
    "in_text = essays.iloc[23].text\n",
    "doc = nlp(in_text)\n",
    "doc._.essay_id = essays.iloc[23]['essay_id']\n",
    "adu24 = adus[adus['essay_id'] == doc._.essay_id]\n",
    "units=segmentation(doc, mode='n_grams', n_grams=15)\n",
    "units=segmentation(doc, mode='sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5a178014",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T19:36:31.462443Z",
     "start_time": "2022-03-05T19:36:31.431093Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utility, Delete Later\n",
    "def print_adus(units):\n",
    "    for i, u in enumerate(units):\n",
    "            unit_start = u._.idx_start\n",
    "            unit_end = u._.idx_end\n",
    "            \n",
    "            essay_id = u.doc._.essay_id\n",
    "            \n",
    "            \n",
    "            doc_adus = adus[adus['essay_id'] == essay_id]\n",
    "             \n",
    "            lis = [((unit_start, unit_end),(row['start_ind'], row['end_ind'], row['ADU_type'],is_adu(unit_start, unit_end, row['start_ind'] ,row['end_ind']))) for row_ind,row in doc_adus.iterrows() if is_adu(unit_start, unit_end, row['start_ind'] ,row['end_ind'])]\n",
    "            \n",
    "            \n",
    "            \n",
    "            if len(lis)>0:\n",
    "                print(i, lis)\n",
    "\n",
    "def verbose_print(units):\n",
    "    # Detailed Printer\n",
    "    \n",
    "    essay_id = units[0].doc._.essay_id\n",
    "    adu_doc = adus[adus['essay_id']==essay_id]\n",
    "    for i, u in enumerate(units):\n",
    "            span_start = u[0].idx\n",
    "            span_end = u[-1].idx  + len(u[-1])\n",
    "\n",
    "            lis = [((span_start, span_end),(row['start_ind'], row['end_ind'], row['ADU_type'],\n",
    "                                            is_adu(span_start, span_end, row['start_ind'] ,row['end_ind'])))\n",
    "                   for row_ind,row in adu_doc.iterrows() if is_adu(span_start, span_end, row['start_ind'] ,row['end_ind'])]\n",
    "            if len(lis)>0:\n",
    "                print(i)\n",
    "                print(lis,\"\\n\")\n",
    "                print(\"UNIT:\",u,\"\\n\")\n",
    "                for ind, adu in enumerate(lis):\n",
    "\n",
    "                    #print(adu[1][2].upper()+':',adu[1][0:2])\n",
    "                    #print(doc.char_span(*adu[1][0:2]), \"\\n\")\n",
    "                    label = adu[1][2].upper() \n",
    "                    adu_range = adu[1][0:2]\n",
    "                    adu_status = adu[1][3]\n",
    "                    print(f'ADU #{ind+1}',label+':',*adu_range, adu_status)\n",
    "                    print(doc.char_span(*adu_range), \"\\n\")\n",
    "                print(\"-----------------\\n\")\n",
    "                \n",
    "def is_adu(unit_start, unit_end, adu_start, adu_end):\n",
    "    \n",
    "    if adu_start<=unit_start and adu_end <=unit_start:\n",
    "        # ADU comes before UNIT\n",
    "        return False\n",
    "    elif adu_start>=unit_end and adu_end >=unit_end:\n",
    "        # ADU comes after UNIT\n",
    "        return False\n",
    "    else:\n",
    "        if adu_start >= unit_start and adu_end <= unit_end:\n",
    "            #print(\"Fully Contains ADU\")\n",
    "            return \"Full\"\n",
    "        elif adu_start <= unit_start and adu_end <=unit_end:\n",
    "            \n",
    "            #print(\"ADU start is cut\")\n",
    "            return \"Start_Cut\"\n",
    "        elif adu_start >= unit_start and adu_end >= unit_end:\n",
    "            # End of ADU is after UNIT\n",
    "            return \"End_Cut\"\n",
    "\n",
    "        elif adu_start <= unit_start and adu_end >= unit_end:\n",
    "\n",
    "            # UNIT is smaller than ADU, ADU start and end are cut\n",
    "            return \"Both_Sides_Cut\"# Utility, Delete Later\n",
    "        \n",
    "# FOR VIEWING ACCURACY ONLY\n",
    "def all_docs(df, segmentation_mode='sentence', label_mode='adu', threshold=0, n_grams=None):\n",
    "    # TEMP\n",
    "    # Rename to create_training_data?\n",
    "    data = [(row['text'], dict(id=row['essay_id'])) for ind, row in df.iterrows()]\n",
    "    docs = []\n",
    "    data\n",
    "    for doc, context in nlp.pipe(data, as_tuples=True):\n",
    "        doc._.essay_id = context['id']\n",
    "        docs.append(doc)\n",
    "    return docs\n",
    "    segmented_docs = [segmentation(doc, mode=segmentation_mode ,n_grams=n_grams) for doc in docs]\n",
    "    \n",
    "    # Flatten lists (Dissolve docs boundaries and store all units together in one huge list)\n",
    "    units = list(chain.from_iterable(segmented_docs))\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b079f343",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T19:36:44.718391Z",
     "start_time": "2022-03-05T19:36:44.662783Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Claim', (0, 1.0, 0))\n",
      "('Premise', (0, 1.0, 0))\n",
      "('Premise', (0, 1.0, 0))\n",
      "('Premise', (0, 1.0, 0))\n",
      "('Claim', (0, 1.0, 0))\n",
      "('Premise', (0, 1.0, 0))\n",
      "('Premise', (0, 1.0, 0))\n",
      "('Claim', (0, 1.0, 0))\n",
      "('Premise', (0, 1.0, 0))\n",
      "('Premise', (0, 1.0, 0))\n",
      "('Premise', (0, 1.0, 0))\n",
      "('Claim', (0, 1.0, 0))\n",
      "('Claim', (0, 1.0, 0))\n"
     ]
    }
   ],
   "source": [
    "units = segmentation(doc, mode='gold_standard')\n",
    "# Coding Error Evaluation\n",
    "start_errors = np.array([])\n",
    "segmentation_accs = np.array([])\n",
    "end_errors = np.array([])\n",
    "\n",
    "for unit in units:\n",
    "    error_tuple = unit._.get_possible_labels()\n",
    "\n",
    "    if len(error_tuple) != 0:\n",
    "        label_position = np.argmax([error[1] for label, error in error_tuple])\n",
    "        \n",
    "        print(error_tuple[label_position])\n",
    "        start_errors = np.append(start_errors,error_tuple[label_position][1][0])\n",
    "        \n",
    "        segmentation_accs = np.append(segmentation_accs, error_tuple[label_position][1][1])\n",
    "        \n",
    "        end_errors = np.append(end_errors, error_tuple[label_position][1][2])\n",
    "        \n",
    "        \n",
    "\n",
    "start_error = sum((start_errors**2))/len(start_errors)\n",
    "\n",
    "end_error = sum((end_errors**2))/len(end_errors)\n",
    "\n",
    "segmentation_acc = segmentation_accs.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3a5dcc82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T21:43:53.770060Z",
     "start_time": "2022-03-05T21:43:53.758072Z"
    }
   },
   "outputs": [],
   "source": [
    "units = segmentation(doc, mode='constituency1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5a8a0380",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T21:44:02.313102Z",
     "start_time": "2022-03-05T21:44:02.262000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.61111111111111, 0.8280923869159164, 82.11111111111111)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_segmentation_accuracy(units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f62f77a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T21:38:41.496052Z",
     "start_time": "2022-03-05T21:38:41.370548Z"
    }
   },
   "outputs": [],
   "source": [
    "t1 = \"This movie is good. I really liked it.\"\n",
    "\n",
    "t2 = \"I hate this movie. It sucks.\"\n",
    "\n",
    "\n",
    "d1 = nlp_trf(t1)\n",
    "d2 = nlp_trf(t2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c1654fd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T21:38:41.623925Z",
     "start_time": "2022-03-05T21:38:41.609923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1.similarity(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "781e019a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T21:33:51.159726Z",
     "start_time": "2022-03-05T21:33:51.152732Z"
    }
   },
   "outputs": [],
   "source": [
    "us = segmentation(doc_trf, 'n_grams', n_grams=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef9f925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b2a7e697",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T21:33:59.842538Z",
     "start_time": "2022-03-05T21:33:59.826825Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "This is a sentence. This is the second sentence"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us[0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "becd018c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T21:32:28.568306Z",
     "start_time": "2022-03-05T21:32:28.556794Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_trf._.trf_data.tensors[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cda759e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T19:36:45.671378Z",
     "start_time": "2022-03-05T19:36:45.647568Z"
    }
   },
   "outputs": [],
   "source": [
    "essays = pd.read_csv('../data/output_csv/essays.csv')\n",
    "\n",
    "\n",
    "n = 100\n",
    "split_pct = 0.8\n",
    "essays = essays.sample(n)\n",
    "train = essays.sample(frac=split_pct)\n",
    "test = essays.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c2d4c61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T20:42:30.283680Z",
     "start_time": "2022-03-05T20:36:49.313702Z"
    }
   },
   "outputs": [],
   "source": [
    "# Smaller set\n",
    "essays = pd.read_csv('../data/output_csv/essays.csv')\n",
    "essays= essays[:50].copy()\n",
    "\n",
    "train = essays[essays['label'] =='train']\n",
    "test =essays[essays['label'] =='test']\n",
    "\n",
    "essays = pd.read_csv('../data/output_csv/essays.csv')\n",
    "\n",
    "\n",
    "n = 200\n",
    "split_pct = 0.7\n",
    "essays = essays.sample(n)\n",
    "train = essays.sample(frac=split_pct)\n",
    "test = essays.drop(train.index)\n",
    "\n",
    "X_train, y_train_adu, y_train_clpr = text2fv(train)\n",
    "\n",
    "\n",
    "X_test, y_test_adu, y_test_clpr = text2fv(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86c2bfbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T20:54:23.984662Z",
     "start_time": "2022-03-05T20:42:30.285679Z"
    }
   },
   "outputs": [],
   "source": [
    "# Smaller set\n",
    "essays = pd.read_csv('../data/output_csv/essays.csv')\n",
    "essays= essays[:50].copy()\n",
    "\n",
    "train = essays[essays['label'] =='train']\n",
    "test =essays[essays['label'] =='test']\n",
    "\n",
    "essays = pd.read_csv('../data/output_csv/essays.csv')\n",
    "\n",
    "\n",
    "n = 200\n",
    "split_pct = 0.7\n",
    "essays = essays.sample(n)\n",
    "train = essays.sample(frac=split_pct)\n",
    "test = essays.drop(train.index)\n",
    "\n",
    "X_train_c, y_train_adu_c, y_train_clpr_c = text2fv(train, segmentation_mode='constituency1')\n",
    "\n",
    "\n",
    "X_test_c, y_test_adu_c, y_test_clpr_c = text2fv(test, segmentation_mode='constituency1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77546d8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T20:57:30.292082Z",
     "start_time": "2022-03-05T20:57:30.284096Z"
    }
   },
   "outputs": [],
   "source": [
    "##Sklearn Models\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57eb288",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e9d63c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T21:02:10.134621Z",
     "start_time": "2022-03-05T21:02:07.195068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Sentence Logreg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADU       0.89      0.98      0.93       801\n",
      "     Non-ADU       0.84      0.52      0.64       200\n",
      "\n",
      "    accuracy                           0.88      1001\n",
      "   macro avg       0.86      0.75      0.78      1001\n",
      "weighted avg       0.88      0.88      0.87      1001\n",
      "\n",
      "Multiclass Sentence Logreg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Claim       0.66      0.66      0.66       289\n",
      "     Non-ADU       0.79      0.56      0.66       200\n",
      "     Premise       0.76      0.85      0.80       512\n",
      "\n",
      "    accuracy                           0.74      1001\n",
      "   macro avg       0.74      0.69      0.71      1001\n",
      "weighted avg       0.74      0.74      0.73      1001\n",
      "\n",
      "Binary Constituency Logreg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADU       0.84      0.91      0.87       888\n",
      "     Non-ADU       0.89      0.80      0.84       791\n",
      "\n",
      "    accuracy                           0.86      1679\n",
      "   macro avg       0.86      0.86      0.86      1679\n",
      "weighted avg       0.86      0.86      0.86      1679\n",
      "\n",
      "Multiclass Constituency Logreg\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Claim       0.56      0.40      0.46       312\n",
      "     Non-ADU       0.86      0.82      0.84       791\n",
      "     Premise       0.65      0.79      0.71       576\n",
      "\n",
      "    accuracy                           0.73      1679\n",
      "   macro avg       0.69      0.67      0.67      1679\n",
      "weighted avg       0.73      0.73      0.72      1679\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Binary Sentence\n",
    "print(\"Binary Sentence Logreg\")\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train_adu)\n",
    "preds1 = logreg.predict(X_test)\n",
    "print(classification_report(y_test_adu, preds1))\n",
    "\n",
    "\n",
    "print(\"Multiclass Sentence Logreg\")\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train_clpr)\n",
    "preds2 = logreg.predict(X_test)\n",
    "print(classification_report(y_test_clpr, preds2))\n",
    "\n",
    "print(\"Binary Constituency Logreg\")\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_c, y_train_adu_c)\n",
    "preds3 = logreg.predict(X_test_c)\n",
    "print(classification_report(y_test_adu_c, preds3))\n",
    "\n",
    "\n",
    "print(\"Multiclass Constituency Logreg\")\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_c, y_train_clpr_c)\n",
    "preds4 = logreg.predict(X_test_c)\n",
    "print(classification_report(y_test_clpr_c, preds4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9167b6",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2447c36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T19:11:26.286547Z",
     "start_time": "2022-03-05T19:11:26.185441Z"
    }
   },
   "outputs": [],
   "source": [
    "##Sklearn Models\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85caf7cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T19:11:26.666834Z",
     "start_time": "2022-03-05T19:11:26.634413Z"
    }
   },
   "outputs": [],
   "source": [
    "essays = pd.read_csv('../data/output_csv/essays.csv')\n",
    "\n",
    "\n",
    "n = 100\n",
    "split_pct = 0.8\n",
    "essays = essays.sample(n)\n",
    "train = essays.sample(frac=split_pct)\n",
    "test = essays.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acb8fdba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T19:11:28.119326Z",
     "start_time": "2022-03-05T19:11:28.097780Z"
    }
   },
   "outputs": [],
   "source": [
    "classifiers = ['LR', 'RF', 'NB', 'XGB', 'SVM']\n",
    "\n",
    "#segmentations = ['sentence', 'paragraph', 'n_grams', 'clause', 'constituency1', 'token', 'gold_standard']3\n",
    "#segmentations = ['sentence', 'n_grams', 'constituency1', 'gold_standard']\n",
    "segmentations = ['sentence']\n",
    "                 \n",
    "#classifications = ['binary', 'multiclass', 'two_binary']\n",
    "classifications = ['binary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8549a05c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T19:11:29.351799Z",
     "start_time": "2022-03-05T19:11:29.322908Z"
    }
   },
   "outputs": [],
   "source": [
    "def pipeline():\n",
    "    \n",
    "    for classification in classifications:\n",
    "        print(classification)\n",
    "        classification_type(classification)\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def classification_type(classification):\n",
    "    \n",
    "    if classification == 'binary':\n",
    "        \n",
    "        for segmentation in segmentations:\n",
    "            print(segmentation)\n",
    "            X_train, y_train = text2fv(train)            \n",
    "            X_test, y_test  = text2fv(test)\n",
    "            train_test_classifer(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    if classification  == 'multiclass':\n",
    "\n",
    "        for segmentation in segmentations:\n",
    "\n",
    "            X_train, y_train = text2fv(train, segmentation_mode=segmentation, label_mode='clpr')\n",
    "            X_test, y_test  = text2fv(test, segmentation_mode=segmentation, label_mode='clpr')\n",
    "            train_test_classifer(X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "    if classification == 'two_binary':\n",
    "\n",
    "        for segmentation in segmentations:\n",
    "\n",
    "            X_train, y_train = text2fv(train, segmentation_mode=segmentation, label_mode='adu')\n",
    "            X_test, y_test  = text2fv(test, segmentation_mode=segmentation, label_mode='adu' )\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "def train_test_classifer(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    for classifier in classifiers:\n",
    "        \n",
    "        if classifier == 'LR':\n",
    "            print(\"logistic_regression\")\n",
    "            logistic_regression(X_train, y_train, X_test, y_test)\n",
    "        \n",
    "        if classifier == 'RF':\n",
    "            print(\"random_forest\")\n",
    "            random_forest(X_train, y_train, X_test, y_test)\n",
    "            \n",
    "        if classifier == 'NB':\n",
    "            print(\"naive_bayes\")\n",
    "            naive_bayes(X_train, y_train, X_test, y_test)\n",
    "        \n",
    "        if classifier == 'XGB':\n",
    "            print(\"xgboost\")\n",
    "            xgboost(X_train, y_train, X_test, y_test)\n",
    "        \n",
    "        if classifier == 'SVM':\n",
    "            print(\"svm\")\n",
    "\n",
    "            svm(X_train, y_train, X_test, y_test)\n",
    "            \n",
    "\n",
    "def logistic_regression(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    logreg = LogisticRegression(solver='newton-cg')\n",
    "    logreg.fit(X_train, y_train)\n",
    "    preds_lr = logreg.predict(X_test)\n",
    "    print(classification_report(y_test, preds_lr))\n",
    "    \n",
    "    ####################################################\n",
    "    # parameter grid\n",
    "    parameters = {\n",
    "        'penalty' : ['l1','l2'], \n",
    "        'C'       : np.logspace(-3,3,7),\n",
    "        'solver'  : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    }\n",
    "    \n",
    "    logreg = LogisticRegression()\n",
    "    clf = GridSearchCV(logreg, \n",
    "                       param_grid=parameters,\n",
    "                       scoring='accuracy',\n",
    "                       cv = 10)\n",
    "    \n",
    "    clf.fit(X_train,y_train)\n",
    "    print(\"Tuned Hyperparameters: \", clf.best_params_)\n",
    "    print(\"Accuracy: \", clf.best_score_)\n",
    "    \n",
    "    preds_lr = clf.predict(X_test)\n",
    "    print(classification_report(y_test, preds_lr))\n",
    "    \n",
    "\n",
    "def random_forest(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    rf = RandomForestClassifier()\n",
    "    rf.fit(X_train, y_train)\n",
    "    preds_rf = rf.predict(X_test)\n",
    "    print(classification_report(y_test, preds_rf))\n",
    "    \n",
    "    ####################################################\n",
    "    # parameter grid\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    print(random_grid)\n",
    "    \n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    # First create the base model to tune\n",
    "    rf = RandomForestClassifier()\n",
    "    # Random search of parameters, using 3 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 2, verbose=2, random_state=42, n_jobs = -1)\n",
    "    # Fit the random search model\n",
    "    rf_random.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Tuned Hyperparameters: \", rf_random.best_params_)\n",
    "    print(\"Accuracy: \", rf_random.best_score_)\n",
    "    \n",
    "    preds_rf_random = rf_random.predict(X_test)\n",
    "    print(classification_report(y_test, preds_rf_random))\n",
    "\n",
    "def naive_bayes(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    #NB doesn't have any hyperparameters to tune.\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(X_train, y_train)\n",
    "    preds_gnb = gnb.predict(X_test)\n",
    "    print(classification_report(y_test, preds_gnb))\n",
    "    \n",
    "\n",
    "def xgboost(X_train, y_train, X_test, y_test):\n",
    "   \n",
    "    xgb_model = XGBClassifier()\n",
    "    xgb_model.fit(X_train, y_train)\n",
    "    y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    ####################################################\n",
    "    # parameter grid\n",
    "    param_grid = {\n",
    "    \"max_depth\": [3, 4, 5, 7],\n",
    "    \"learning_rate\": [0.1, 0.01, 0.05],\n",
    "    \"gamma\": [0, 0.25, 1],\n",
    "    \"reg_lambda\": [0, 1, 10],\n",
    "    \"scale_pos_weight\": [1, 3, 5],\n",
    "    \"subsample\": [0.8],\n",
    "    \"colsample_bytree\": [0.5],\n",
    "    }\n",
    "\n",
    "    # Init classifier\n",
    "    xgb_cl = XGBClassifier()\n",
    "    # Init Grid Search\n",
    "    grid_xgb = GridSearchCV(xgb_cl, param_grid, n_jobs=-1, cv=3)\n",
    "    xgb_grid = grid_xgb.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    print(\"Tuned Hyperparameters: \", xgb_grid.best_params_)\n",
    "    print(\"Accuracy: \", xgb_grid.best_score_)\n",
    "\n",
    "    y_pred = xgb_grid.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "\n",
    "def svm(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    clf = SVC()\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    \n",
    "    ####################################################\n",
    "    # parameter grid\n",
    "    # defining parameter range\n",
    "    param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "                  'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "                  'kernel': ['linear', 'poly', 'rbf', 'sigmoid']}\n",
    "\n",
    "    svm_grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "\n",
    "    # fitting the model for grid search\n",
    "    svm_grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Tuned Hyperparameters: \", svm_grid.best_params_)\n",
    "    print(\"Accuracy: \", svm_grid.best_score_)\n",
    "\n",
    "    y_pred = svm_grid.predict(X_test)\n",
    "\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "914d9703",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-05T19:22:40.940273Z",
     "start_time": "2022-03-05T19:11:41.522728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary\n",
      "sentence\n",
      "logistic_regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADU       0.90      0.96      0.92       268\n",
      "     Non-ADU       0.76      0.56      0.64        68\n",
      "\n",
      "    accuracy                           0.88       336\n",
      "   macro avg       0.83      0.76      0.78       336\n",
      "weighted avg       0.87      0.88      0.87       336\n",
      "\n",
      "Tuned Hyperparameters:  {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}\n",
      "Accuracy:  0.8841002856236116\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADU       0.87      0.98      0.92       268\n",
      "     Non-ADU       0.84      0.40      0.54        68\n",
      "\n",
      "    accuracy                           0.86       336\n",
      "   macro avg       0.85      0.69      0.73       336\n",
      "weighted avg       0.86      0.86      0.84       336\n",
      "\n",
      "random_forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ADU       0.86      0.99      0.92       268\n",
      "     Non-ADU       0.89      0.37      0.52        68\n",
      "\n",
      "    accuracy                           0.86       336\n",
      "   macro avg       0.88      0.68      0.72       336\n",
      "weighted avg       0.87      0.86      0.84       336\n",
      "\n",
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BILALM~1\\AppData\\Local\\Temp/ipykernel_6940/1150355636.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\BILALM~1\\AppData\\Local\\Temp/ipykernel_6940/2380300528.py\u001b[0m in \u001b[0;36mpipeline\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mclassification\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclassifications\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mclassification_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\BILALM~1\\AppData\\Local\\Temp/ipykernel_6940/2380300528.py\u001b[0m in \u001b[0;36mclassification_type\u001b[1;34m(classification)\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext2fv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mtext2fv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mtrain_test_classifer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mclassification\u001b[0m  \u001b[1;33m==\u001b[0m \u001b[1;34m'multiclass'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\BILALM~1\\AppData\\Local\\Temp/ipykernel_6940/2380300528.py\u001b[0m in \u001b[0;36mtrain_test_classifer\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'RF'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"random_forest\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[0mrandom_forest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'NB'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\BILALM~1\\AppData\\Local\\Temp/ipykernel_6940/2380300528.py\u001b[0m in \u001b[0;36mrandom_forest\u001b[1;34m(X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m    131\u001b[0m     \u001b[0mrf_random\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_distributions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[1;31m# Fit the random search model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m     \u001b[0mrf_random\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Tuned Hyperparameters: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_random\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1631\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m         \u001b[1;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1633\u001b[1;33m         evaluate_candidates(ParameterSampler(\n\u001b[0m\u001b[0;32m   1634\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1635\u001b[0m             random_state=self.random_state))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    438\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 440\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    441\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
